{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvAgg10/Python-projects/blob/main/turboengine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clXoDZZV3zji"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "#import random forest regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#import test train split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_paths = {\n",
        "    \"FD001\": \"/content/train_FD001.txt\",\n",
        "    \"FD002\": \"/content/train_FD002.txt\",\n",
        "    \"FD003\": \"/content/train_FD003.txt\",\n",
        "    \"FD004\": \"/content/train_FD004.txt\"\n",
        "}"
      ],
      "metadata": {
        "id": "K-Zz1pux9E0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without sep=' '\n",
        "\n",
        "When you do not specify the sep parameter, pandas assumes the default separator (a comma , for CSV files).\n",
        "\n",
        "Since your file is space-separated, pandas reads the entire row as a single column, resulting in only one column.\n",
        "\n",
        "With sep=' '\n",
        "\n",
        "By specifying sep=' ' (space separator), pandas correctly interprets spaces as column dividers and properly separates the data into multiple columns."
      ],
      "metadata": {
        "id": "2lICWB6Z7LHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column Headers for Train Data\n",
        "\n",
        "Unit Number – Unique identifier for each engine\n",
        "\n",
        "Time (cycles) – The number of operational cycles completed\n",
        "\n",
        "Operational Setting 1\n",
        "\n",
        "Operational Setting 2\n",
        "\n",
        "Operational Setting 3 6-26. Sensor Measurements 1 to 26 – Various engine sensor readings"
      ],
      "metadata": {
        "id": "4-5GabA-7S_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# List to store processed datasets\n",
        "datasets = []\n",
        "\n",
        "column_names = [\n",
        "    \"unit_number\", \"time_in_cycles\",\n",
        "    \"operational_setting_1\", \"operational_setting_2\", \"operational_setting_3\"\n",
        "] + [f\"sensor_{i}\" for i in range(1, 22)]\n",
        "\n",
        "for dataset_id, path in dataset_paths.items():\n",
        "    df = pd.read_csv(path, sep='\\s+', header=None)\n",
        "    df.columns = column_names\n",
        "    df['dataset_id'] = dataset_id\n",
        "\n",
        "    # Make unit_number unique by appending dataset_id\n",
        "    df['unit_number'] = df['unit_number'].astype(str) + \"_\" + dataset_id\n",
        "\n",
        "    # Compute RUL separately\n",
        "    df['RUL'] = df.groupby(\"unit_number\")[\"time_in_cycles\"].transform(max) - df[\"time_in_cycles\"]\n",
        "\n",
        "    datasets.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6BhaiEI6O7f",
        "outputId": "c467fa61-a8bb-4986-ae2b-49859fcc6e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c3796b45c788>:18: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  df['RUL'] = df.groupby(\"unit_number\")[\"time_in_cycles\"].transform(max) - df[\"time_in_cycles\"]\n",
            "<ipython-input-3-c3796b45c788>:18: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  df['RUL'] = df.groupby(\"unit_number\")[\"time_in_cycles\"].transform(max) - df[\"time_in_cycles\"]\n",
            "<ipython-input-3-c3796b45c788>:18: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  df['RUL'] = df.groupby(\"unit_number\")[\"time_in_cycles\"].transform(max) - df[\"time_in_cycles\"]\n",
            "<ipython-input-3-c3796b45c788>:18: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  df['RUL'] = df.groupby(\"unit_number\")[\"time_in_cycles\"].transform(max) - df[\"time_in_cycles\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all datasets into one\n",
        "merged_data = pd.concat(datasets, ignore_index=True)\n",
        "\n",
        "print(f\"Merged dataset shape: {merged_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZFfXxqD9eC2",
        "outputId": "5a920cf0-cf7d-4e3e-d950-436ae4740ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset shape: (160359, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Merge all datasets\n",
        "merged_data = pd.concat(datasets, ignore_index=True)\n",
        "\n",
        "print(merged_data[['unit_number', 'dataset_id', 'RUL']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhqEY7Eo-QfX",
        "outputId": "54c77304-a312-43d6-9f28-dc22b6172f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  unit_number dataset_id  RUL\n",
            "0     1_FD001      FD001  191\n",
            "1     1_FD001      FD001  190\n",
            "2     1_FD001      FD001  189\n",
            "3     1_FD001      FD001  188\n",
            "4     1_FD001      FD001  187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_data['unit_number'].unique()[:10])  # Check first 10 unique engines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AivHOrC_-xz_",
        "outputId": "66118d0a-4108-484b-88ec-7fdfb1ce836f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1_FD001' '2_FD001' '3_FD001' '4_FD001' '5_FD001' '6_FD001' '7_FD001'\n",
            " '8_FD001' '9_FD001' '10_FD001']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_mapping = {\"FD001\": 1, \"FD002\": 2, \"FD003\": 3, \"FD004\": 4}\n",
        "merged_data[\"dataset_id\"] = merged_data[\"dataset_id\"].map(dataset_mapping)"
      ],
      "metadata": {
        "id": "jgCqmgANAlKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check failure cycles for Engine 1 in each dataset\n",
        "for dataset_id in [1, 2, 3, 4]:\n",
        "    engine_1_max_cycles = merged_data[merged_data['unit_number'] == f'1_{dataset_id}']['time_in_cycles'].max()\n",
        "    print(f\"Engine 1 in {dataset_id} failed after {engine_1_max_cycles} cycles.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LSFCKRX6dV_",
        "outputId": "1aa5cb0d-f740-4c97-b936-2305c3a7025a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engine 1 in 1 failed after nan cycles.\n",
            "Engine 1 in 2 failed after nan cycles.\n",
            "Engine 1 in 3 failed after nan cycles.\n",
            "Engine 1 in 4 failed after nan cycles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUfE-ura6TEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425c7358-cf39-4888-9e7a-04788f09b208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (128287, 25)\n",
            "Validation data shape: (32072, 25)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature columns (excluding unit_number, time_in_cycles, and RUL)\n",
        "features = [col for col in merged_data.columns if col not in ['unit_number', 'time_in_cycles', 'RUL']]\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X = merged_data[features]\n",
        "y = merged_data['RUL']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Train LightGBM model\n",
        "lgbm_model = LGBMRegressor(n_estimators=200, learning_rate=0.05, max_depth=7, random_state=42)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training completed! ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBPGnENp_y1G",
        "outputId": "6d7fc0ee-ed53-4e28-8d4c-394a65695d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012004 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3845\n",
            "[LightGBM] [Info] Number of data points in the train set: 128287, number of used features: 25\n",
            "[LightGBM] [Info] Start training from score 122.275110\n",
            "Model training completed! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "itkWdcP06xv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5151c7fc-7ec8-4ba9-d190-d6f1489f1a4b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training completed! ✅\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"Model training completed! ✅\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"Model training completed! ✅\")\n"
      ],
      "metadata": {
        "id": "kCd1K4HpAOoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e9c8b9-a7f3-4199-c137-fb99ac0f6c8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training completed! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Qna53z8H6zYZ"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Store trained models in a dictionary\n",
        "models = {\n",
        "    \"LightGBM\": lgbm_model,\n",
        "    \"XGBoost\": xgb_model,\n",
        "    \"Random Forest\": rf_model\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    # Predict on validation set\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # Compute MAE & RMSE\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "\n",
        "    # Print results\n",
        "    print(f\"🔹 {model_name} Results:\")\n",
        "    print(f\"   ✅ Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"   ✅ Root Mean Squared Error (RMSE): {rmse:.2f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVkw8UYwCl0t",
        "outputId": "5949c2ea-edb6-4122-ec3f-0c856a74b45b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 LightGBM Results:\n",
            "   ✅ Mean Absolute Error (MAE): 35.84\n",
            "   ✅ Root Mean Squared Error (RMSE): 50.17\n",
            "\n",
            "🔹 XGBoost Results:\n",
            "   ✅ Mean Absolute Error (MAE): 36.28\n",
            "   ✅ Root Mean Squared Error (RMSE): 50.64\n",
            "\n",
            "🔹 Random Forest Results:\n",
            "   ✅ Mean Absolute Error (MAE): 35.57\n",
            "   ✅ Root Mean Squared Error (RMSE): 50.15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define test dataset paths\n",
        "test_paths = {\n",
        "    \"FD001\": \"/content/test_FD001.txt\",\n",
        "    \"FD002\": \"/content/test_FD002.txt\",\n",
        "    \"FD003\": \"/content/test_FD003.txt\",\n",
        "    \"FD004\": \"/content/test_FD004.txt\"\n",
        "}\n",
        "\n",
        "# Define true RUL paths\n",
        "rul_paths = {\n",
        "    \"FD001\": \"/content/RUL_FD001.txt\",\n",
        "    \"FD002\": \"/content/RUL_FD002.txt\",\n",
        "    \"FD003\": \"/content/RUL_FD003.txt\",\n",
        "    \"FD004\": \"/content/RUL_FD004.txt\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "09Ufs17WCnyd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each test dataset separately\n",
        "test_datasets = []\n",
        "\n",
        "for dataset_id, path in test_paths.items():\n",
        "    # Load test dataset\n",
        "    test_df = pd.read_csv(path, sep='\\s+', header=None)\n",
        "\n",
        "    # Assign column names\n",
        "    test_df.columns = column_names\n",
        "\n",
        "    # Keep only the last cycle for each engine\n",
        "    test_df = test_df.groupby(\"unit_number\").last().reset_index()\n",
        "\n",
        "    # Make unit_number unique by appending dataset_id\n",
        "    test_df[\"unit_number\"] = test_df[\"unit_number\"].astype(str) + \"_\" + dataset_id\n",
        "\n",
        "    # Convert dataset_id to numeric\n",
        "    test_df[\"dataset_id\"] = dataset_mapping[dataset_id]\n",
        "\n",
        "    # Load true RUL values\n",
        "    true_rul = pd.read_csv(rul_paths[dataset_id], header=None, names=[\"True_RUL\"])\n",
        "\n",
        "    # Add true RUL to test data\n",
        "    test_df[\"True_RUL\"] = true_rul[\"True_RUL\"]\n",
        "\n",
        "    # Append to list\n",
        "    test_datasets.append(test_df)\n"
      ],
      "metadata": {
        "id": "EtQOF-OkDE7A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all test datasets\n",
        "merged_test_data = pd.concat(test_datasets, ignore_index=True)\n",
        "\n",
        "print(f\" Merged test dataset shape: {merged_test_data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj7-CB6bDV5N",
        "outputId": "26155808-e2e0-497a-9dbd-dd1f762eb600"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Merged test dataset shape: (707, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_test_data[['unit_number', 'dataset_id', 'operational_setting_1', 'operational_setting_2', 'operational_setting_3']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSSj7mLZDX82",
        "outputId": "7d013114-5b8a-4166-993c-6efe7cbf2237"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  unit_number  dataset_id  operational_setting_1  operational_setting_2  \\\n",
            "0     1_FD001           1                -0.0006                 0.0004   \n",
            "1     2_FD001           1                 0.0018                -0.0001   \n",
            "2     3_FD001           1                -0.0016                 0.0004   \n",
            "3     4_FD001           1                 0.0012                 0.0004   \n",
            "4     5_FD001           1                -0.0013                -0.0004   \n",
            "5     6_FD001           1                 0.0076                -0.0003   \n",
            "6     7_FD001           1                 0.0016                -0.0001   \n",
            "7     8_FD001           1                 0.0016                -0.0005   \n",
            "8     9_FD001           1                -0.0003                 0.0004   \n",
            "9    10_FD001           1                -0.0018                 0.0004   \n",
            "\n",
            "   operational_setting_3  \n",
            "0                  100.0  \n",
            "1                  100.0  \n",
            "2                  100.0  \n",
            "3                  100.0  \n",
            "4                  100.0  \n",
            "5                  100.0  \n",
            "6                  100.0  \n",
            "7                  100.0  \n",
            "8                  100.0  \n",
            "9                  100.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through models and evaluate on test data\n",
        "for model_name, model in models.items():\n",
        "    # Predict RUL\n",
        "    merged_test_data[f\"Predicted_RUL_{model_name}\"] = model.predict(X_test)\n",
        "\n",
        "    # Compute MAE & RMSE\n",
        "    mae = mean_absolute_error(merged_test_data[\"True_RUL\"], merged_test_data[f\"Predicted_RUL_{model_name}\"])\n",
        "    rmse = np.sqrt(mean_squared_error(merged_test_data[\"True_RUL\"], merged_test_data[f\"Predicted_RUL_{model_name}\"]))\n",
        "\n",
        "    print(f\"✅ {model_name} Test Accuracy Results:\")\n",
        "    print(f\"   🔹 Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"   🔹 Root Mean Squared Error (RMSE): {rmse:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtDfWLAbDeSy",
        "outputId": "62820814-5565-49ac-dccf-9f33ac910dc4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LightGBM Test Accuracy Results:\n",
            "   🔹 Mean Absolute Error (MAE): 27.60\n",
            "   🔹 Root Mean Squared Error (RMSE): 37.83\n",
            "\n",
            "✅ XGBoost Test Accuracy Results:\n",
            "   🔹 Mean Absolute Error (MAE): 28.92\n",
            "   🔹 Root Mean Squared Error (RMSE): 38.83\n",
            "\n",
            "✅ Random Forest Test Accuracy Results:\n",
            "   🔹 Mean Absolute Error (MAE): 27.54\n",
            "   🔹 Root Mean Squared Error (RMSE): 38.66\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ If MAE < 30 & RMSE < 50, model is industry-ready ✅"
      ],
      "metadata": {
        "id": "3ZuuppNAEKiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function to predict RUL based on user input\n",
        "def predict_rul(op1, op2, op3, sensor_values, dataset_id):\n",
        "    \"\"\"\n",
        "    Predicts Remaining Useful Life (RUL) given operational settings and sensor values.\n",
        "\n",
        "    Parameters:\n",
        "    - op1, op2, op3: Operational settings\n",
        "    - sensor_values: List of 21 sensor readings\n",
        "    - dataset_id: Numeric ID of dataset (1=FD001, 2=FD002, 3=FD003, 4=FD004)\n",
        "\n",
        "    Returns:\n",
        "    - Predicted RUL\n",
        "    \"\"\"\n",
        "    # Ensure input matches the model's expected feature format\n",
        "    input_data = np.array([[op1, op2, op3] + sensor_values + [dataset_id]])\n",
        "\n",
        "    # Predict RUL using the trained LightGBM model\n",
        "    predicted_rul = lgbm_model.predict(input_data)[0]\n",
        "\n",
        "    return predicted_rul"
      ],
      "metadata": {
        "id": "Gd4yL4SyFxfs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Manually enter values\n",
        "op1 = float(input(\"Enter Operational Setting 1: \"))\n",
        "op2 = float(input(\"Enter Operational Setting 2: \"))\n",
        "op3 = float(input(\"Enter Operational Setting 3: \"))\n",
        "\n",
        "# Get sensor values as a list\n",
        "sensor_values = []\n",
        "for i in range(1, 22):  # Assuming 21 sensors\n",
        "    value = float(input(f\"Enter Sensor {i} Value: \"))\n",
        "    sensor_values.append(value)\n",
        "\n",
        "# Select dataset ID\n",
        "dataset_id = int(input(\"Enter Dataset ID (1=FD001, 2=FD002, 3=FD003, 4=FD004): \"))\n",
        "\n",
        "# Predict RUL\n",
        "predicted_rul = predict_rul(op1, op2, op3, sensor_values, dataset_id)\n",
        "\n",
        "print(f\" Predicted RUL: {predicted_rul:.2f} cycles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp6613VBFxzY",
        "outputId": "68c8e734-0e30-48a5-f6f9-9ade5f3f936c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Operational Setting 1: 1\n",
            "Enter Operational Setting 2: 2\n",
            "Enter Operational Setting 3: -0.0027\n",
            "Enter Sensor 1 Value: -0.0003\n",
            "Enter Sensor 2 Value: 100.0\n",
            "Enter Sensor 3 Value: 518.67\n",
            "Enter Sensor 4 Value: 641.71\n",
            "Enter Sensor 5 Value: 1588.45\n",
            "Enter Sensor 6 Value: 1395.42\n",
            "Enter Sensor 7 Value: 14.62\n",
            "Enter Sensor 8 Value:  21.61\n",
            "Enter Sensor 9 Value: 554.85\n",
            "Enter Sensor 10 Value: 2388.01\n",
            "Enter Sensor 11 Value: 9054.42\n",
            "Enter Sensor 12 Value: 1.30\n",
            "Enter Sensor 13 Value: 47.50\n",
            "Enter Sensor 14 Value:  522.16\n",
            "Enter Sensor 15 Value: 2388.06\n",
            "Enter Sensor 16 Value: 8139.62\n",
            "Enter Sensor 17 Value: 8.3803\n",
            "Enter Sensor 18 Value: 0.03\n",
            "Enter Sensor 19 Value: 393\n",
            "Enter Sensor 20 Value: 2388\n",
            "Enter Sensor 21 Value:  100.00\n",
            "Enter Dataset ID (1=FD001, 2=FD002, 3=FD003, 4=FD004): 1\n",
            " Predicted RUL: 121.37 cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 2 -0.0027 -0.0003 100.0 518.67 641.71 1588.45 1395.42 14.62 21.61 554.85 2388.01 9054.42 1.30 47.50 522.16 2388.06 8139.62 8.3803 0.03 393 2388 100.00 39.02 23.3916  "
      ],
      "metadata": {
        "id": "NCXZWGWFG5Ds"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2IY5YyYF0M5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5gJZJMlFaj4C/SwVXU6WQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}